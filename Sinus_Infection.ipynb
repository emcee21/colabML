{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sinus Infection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLvfuhsZ6XJ35YShX1BUyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emcee21/colabML/blob/master/Sinus_Infection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXYiiiXXkwGs",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import randint, uniform\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "\n",
        "\n",
        "#@title Example form fields\n",
        "#@markdown Forms support many types of fields.\n",
        "\n",
        "# number N of points where a curve is sampled  \n",
        "SAMPLE_LEN =    64#@param {type: \"integer\"} \n",
        "\n",
        "# number of curves in the training set\n",
        "SAMPLE_SIZE = 32768   #@param {type: \"integer\"} \n",
        "\n",
        "# least ordinate where to sample\n",
        "X_MIN = -5.0  #@param {type: \"number\"} \n",
        "# last ordinate where to sample\n",
        "X_MAX = 5.0   #@param {type: \"number\"} \n",
        "\n",
        "\n",
        "BATCH =        8172#@param {type: \"integer\"}\n",
        "EPOCHS =    65536#@param {type: \"integer\"}\n",
        "\n",
        "DISCRIMINATOR_DROPOUT_RATE = 0.25  #@param {type: \"number\"}\n",
        "GENERATOR_LEAK_RATE = 0.1  #@param {type: \"number\"}\n",
        " \n",
        "DISCRIMINATOR_LEARNING_RATE = 0.2  #@param {type: \"number\"}\n",
        "GENERATOR_LEARNING_RATE = 0.004  #@param {type: \"number\"}\n",
        "\n",
        "EPSILON = 0.0000001  #@param {type: \"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "# The set of coordinates over which curves are sampled\n",
        "X_COORDS = np.linspace(X_MIN , X_MAX, SAMPLE_LEN)\n",
        " \n",
        "# The training set\n",
        "SAMPLE = np.zeros((SAMPLE_SIZE, SAMPLE_LEN))\n",
        "for i in range(0, SAMPLE_SIZE):\n",
        "    b = uniform(0.5, 2.0)\n",
        "    c = uniform(np.math.pi)\n",
        "    SAMPLE[i] = np.array([np.sin(b*x + c) for x in X_COORDS])\n",
        " \n",
        "# We plot the first 8 curves\n",
        "fig, axis = plt.subplots(1, 1)\n",
        "for i in range(8):\n",
        "    axis.plot(X_COORDS, SAMPLE[i])\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgIlQsJmQwzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(f'SAMPLE_LEN={SAMPLE_LEN}')\n",
        "print(f'SAMPLE_SIZE={SAMPLE_SIZE}')\n",
        "print(f'X_MIN={X_MIN}')\n",
        "print(f'X_MAX={X_MAX}')\n",
        "print(f'BATCH={BATCH}')\n",
        "print(f'EPOCHS={EPOCHS}')\n",
        "print(f'DISCRIMINATOR_DROPOUT_RATE={DISCRIMINATOR_DROPOUT_RATE}')\n",
        "print(f'GENERATOR_LEAK_RATE={GENERATOR_LEAK_RATE}')\n",
        "print(f'DISCRIMINATOR_LEARNING_RATE={DISCRIMINATOR_LEARNING_RATE}')\n",
        "print(f'GENERATOR_LEARNING_RATE={GENERATOR_LEARNING_RATE}')\n",
        "print(f'EPSILON={EPSILON}')\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        " \n",
        "DROPOUT = Dropout(DISCRIMINATOR_DROPOUT_RATE)        # Empirical hyperparameter\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Dense(SAMPLE_LEN))\n",
        "discriminator.add(DROPOUT)\n",
        "discriminator.add(Dense(512))\n",
        "discriminator.add(DROPOUT)\n",
        "discriminator.add(Dense(1, activation = \"sigmoid\"))\n",
        "discriminator.compile(optimizer = Adam(learning_rate=DISCRIMINATOR_LEARNING_RATE, epsilon = EPSILON), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "LEAKY_RELU = LeakyReLU(GENERATOR_LEAK_RATE)   # Empirical hyperparameter\n",
        "generator = Sequential()\n",
        "generator.add(Dense(SAMPLE_LEN))\n",
        "generator.add(LEAKY_RELU)\n",
        "generator.add(Dense(512))\n",
        "generator.add(LEAKY_RELU)\n",
        "generator.add(Dense(SAMPLE_LEN, activation = \"tanh\"))\n",
        "#generator.compile(optimizer = Adam(learning_rate=GENERATOR_LEARNING_RATE, epsilon = EPSILON), loss = \"mse\", metrics = [\"accuracy\"])\n",
        "#generator.compile()\n",
        "\n",
        "gan = Sequential()\n",
        "gan.add(generator)\n",
        "gan.add(discriminator)\n",
        "gan.compile(optimizer = Adam(learning_rate=GENERATOR_LEARNING_RATE, epsilon = EPSILON), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "NOISE = uniform(X_MIN, X_MAX, size = (SAMPLE_SIZE, SAMPLE_LEN))\n",
        "ONES = np.ones((SAMPLE_SIZE))\n",
        "ZEROS = np.zeros((SAMPLE_SIZE))\n",
        "print(\"epoch | dis. loss | dis. acc | gen. loss | gen. acc\")\n",
        "print(\"------+-----------+----------+-----------+----------\")\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCHES_PER_EPOCH = (SAMPLE_SIZE // BATCH)\n",
        "g_losses = np.zeros(([EPOCHS * BATCHES_PER_EPOCH]))\n",
        "g_accuracy = np.zeros(([EPOCHS * BATCHES_PER_EPOCH]))\n",
        "d_losses = np.zeros(([EPOCHS * BATCHES_PER_EPOCH]))\n",
        "d_accuracy = np.zeros(([EPOCHS * BATCHES_PER_EPOCH]))\n",
        "\n",
        "\n",
        "\n",
        "ax_index = 1\n",
        "stats_index = 0\n",
        "for e in range(EPOCHS):\n",
        "    for k in range(BATCHES_PER_EPOCH):\n",
        "        # Addestra il discriminatore a riconoscere le sinusoidi vere da quelle prodotte dal generatore\n",
        "        n = randint(0, SAMPLE_SIZE, size = BATCH)\n",
        "        # Ora prepara un batch di training record per il discriminatore\n",
        "        p = generator.predict(NOISE[n])\n",
        "        #p1 = discriminator.predict(SAMPLE[n])\n",
        "        x = np.concatenate((SAMPLE[n], p))\n",
        "        y = np.concatenate((ONES[n], ZEROS[n]))\n",
        "        d_result = discriminator.train_on_batch(x, y)\n",
        "        d_losses.put([stats_index],[d_result[0]])\n",
        "        d_accuracy.put(stats_index,d_result[1])\n",
        "\n",
        "        #p2 = discriminator.predict(x)\n",
        "        discriminator.trainable = False\n",
        "        g_result = gan.train_on_batch(NOISE[n], ONES[n])\n",
        "        g_losses.put(stats_index, g_result[0])\n",
        "        g_accuracy.put(stats_index, g_result[1])\n",
        "\n",
        "        discriminator.trainable = True\n",
        "        stats_index += 1\n",
        "\n",
        "    print(f\" {e:04n} |  {d_result[0]:.5f}  |  {d_result[1]:.5f} |  {g_result[0]:.5f}  |  {g_result[1]:.5f}\")\n",
        "    # At 3, 13, 23, ... plots the last generator prediction\n",
        "    if e % 10 == 3:\n",
        "        #print(f\"{generator.metrics_names}\")\n",
        "        #print(f\"{discriminator.metrics_names}\")\n",
        "        #print(f\"{gan.metrics_names}\")\n",
        "        #print(f\"p1 sum={p1.sum()}\")\n",
        "        #print(f\"p2 sum={p2.sum()}\")\n",
        "\n",
        "        #gan.summary()\n",
        "\n",
        "        fig, axs = plt.subplots(3, 1, figsize= (8, 12))\n",
        "\n",
        "        ax = axs[0]\n",
        "        ax.plot(X_COORDS, p[-1])\n",
        "        #print(p[-1])\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.set_ylabel(f\"Epoch: {e}\")\n",
        "\n",
        "#        ax = losses_fig.add_subplot(EPOCHS + 1 / 10 , 1, ax_index)\n",
        "        ax = axs[1]\n",
        "        ax.plot(log(d_losses[0:stats_index - 1]))\n",
        "        ax.plot(log(g_losses[0:stats_index - 1]))\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.set_ylabel(f\"Losses Epoch: {e}\")\n",
        "\n",
        "#        ax = accuracy_fig.add_subplot(EPOCHS + 1 / 10 , 1, ax_index)\n",
        "        ax = axs[2]\n",
        "        ax.plot(d_accuracy[0:stats_index - 1])\n",
        "        ax.plot(g_accuracy[0:stats_index - 1])\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.set_ylabel(f\"Accuracy Epoch: {e}\")\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "        ax_index += 1\n",
        "\n",
        "\n",
        "# Plots a curve generated by the GAN\n",
        "y = generator.predict(uniform(X_MIN, X_MAX, size = (1, SAMPLE_LEN)))[0]\n",
        "ax = fig.add_subplot(EPOCHS + 1 / 10, 1, ax_index)\n",
        "plt.plot(X_COORDS, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZm5ocBzQrAo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}